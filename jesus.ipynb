{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sl1wL0qSvq49"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtbuyOGnImo9"
      },
      "outputs": [],
      "source": [
        "pip install torchtext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtQzSS9fvq4_"
      },
      "outputs": [],
      "source": [
        "pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpVrPxqWImo_"
      },
      "outputs": [],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z95u1wuvq5A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "# Read the text file\n",
        "with open('./data/sherlock-holm.es_stories_plain-text_advs.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "    text = text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHk7tqGUImpB"
      },
      "outputs": [],
      "source": [
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y3AZdfIvq5B"
      },
      "outputs": [],
      "source": [
        "tokens = word_tokenize(text)\n",
        "vocabulary = set(tokens)\n",
        "total_words = len(vocabulary) + 1\n",
        "\n",
        "word_to_idx = {word:idx for idx, word in enumerate(vocabulary)}\n",
        "\n",
        "print(f\"total_words: {total_words}\")\n",
        "print(\"Índice de palabras:\", word_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujpIb48zvq5C"
      },
      "outputs": [],
      "source": [
        "input_sequences = []\n",
        "for line in text.split('\\n'):\n",
        "    line_list = line.rstrip(\",.;:\").split(' ')\n",
        "    token_list = []\n",
        "    for char in line_list:\n",
        "        if char in word_to_idx.keys():\n",
        "            token_list.append(word_to_idx[char])\n",
        "\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHKYG7myImpE"
      },
      "outputs": [],
      "source": [
        "# Imprimiendo las secuencias de n-gramas\n",
        "print(f\"Secuencias de n-gramas: {input_sequences[:5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXz72d7xImpF"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hC6mO3iZvq5C"
      },
      "outputs": [],
      "source": [
        "# Determinamos la longitud máxima de las secuencias.\n",
        "max_sequence_len = max(len(seq) for seq in input_sequences)\n",
        "\n",
        "# Añadimos padding al principio de cada secuencia.\n",
        "padded_sequences = []\n",
        "for seq in input_sequences:\n",
        "    num_padding = max_sequence_len - len(seq)\n",
        "    padded_seq = [0] * num_padding + seq\n",
        "    padded_sequences.append(padded_seq)\n",
        "\n",
        "# Convertimos las secuencias en tensores.\n",
        "tensor_sequences = torch.tensor(padded_sequences)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJc5edc_ImpH"
      },
      "outputs": [],
      "source": [
        "print(f\"max_sequence_len: {max_sequence_len}\")\n",
        "print(f\"Secuencias de n-gramas: {tensor_sequences[:5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ik9w1hVFvq5C"
      },
      "outputs": [],
      "source": [
        "X = tensor_sequences[:, :-1]\n",
        "y = tensor_sequences[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84XttU1xImpI"
      },
      "outputs": [],
      "source": [
        "print(X)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RdpLwhZImpI"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6t5_IDkvq5C"
      },
      "outputs": [],
      "source": [
        "# Convertir las etiquetas a one-hot encoding\n",
        "num_classes = y.max().item() + 1  # Determinar el número de clases\n",
        "y = F.one_hot(y, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6BoRSQ3ImpJ"
      },
      "outputs": [],
      "source": [
        "print(\"Secuencias con padding (X):\")\n",
        "print(X)\n",
        "print(\"Etiquetas (y) en one-hot encoding:\")\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uif9xg1Pvq5D"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjfEyHznvq5D"
      },
      "outputs": [],
      "source": [
        "dataset = TextDataset(X, y)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV3LoF5vvq5D"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, total_words, embedding_dim, hidden_dim, output_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(total_words, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        lstm_out , _ = self.lstm(x)\n",
        "        lstm_out = lstm_out[:, -1, :]\n",
        "        x = self.fc(lstm_out)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68q7DcENvq5D"
      },
      "outputs": [],
      "source": [
        "model = LSTMModel(total_words, 100, 150, total_words)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtXHht7Jvq5D"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloader, criterion, optimizer, epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, torch.max(y_batch, 1)[1])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE5-kuPavq5D"
      },
      "outputs": [],
      "source": [
        "train_model(model, dataloader, criterion, optimizer, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKkCBkHgvq5E"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "#Guardar modelo\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "#Guardar tokenizer\n",
        "import pickle\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(word_to_idx, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK6vJX5dImpO",
        "outputId": "e62e1447-dc67-4e99-f5ff-1290dbbc3031"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPcGBsB4vq5E",
        "outputId": "ab62dafb-e4f7-432a-8f9f-20e0f23d811c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I will leave if they the the the\n"
          ]
        }
      ],
      "source": [
        "# Texto inicial y número de palabras a predecir\n",
        "seed_text = \"I will leave if they\"\n",
        "next_words = 3\n",
        "\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
        "\n",
        "# Tokenizamos el seed_text y lo convertimos a índices\n",
        "tokens = word_tokenize(seed_text)\n",
        "input_sequence = [word_to_idx[word] for word in tokens if word in word_to_idx]\n",
        "\n",
        "# Generamos las siguientes palabras\n",
        "model.eval()  # Configuramos el modelo en modo evaluación\n",
        "for _ in range(next_words):\n",
        "    # Convertimos la secuencia de entrada a tensor y añadimos una dimensión\n",
        "    input_tensor = torch.tensor(input_sequence).unsqueeze(0)\n",
        "\n",
        "    # Realizamos la predicción con el modelo\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "\n",
        "    # Obtenemos el índice de la palabra predicha\n",
        "    predicted_idx = torch.argmax(output, dim=1).item()\n",
        "\n",
        "    # Añadimos la palabra predicha a la secuencia de entrada\n",
        "    input_sequence.append(predicted_idx)\n",
        "\n",
        "    # Añadimos la palabra predicha al texto semilla\n",
        "    word = idx_to_word[predicted_idx]\n",
        "    seed_text += \" \" + word\n",
        "\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
