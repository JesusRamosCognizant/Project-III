{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Example:  \n",
    "Model:      MD1  \n",
    "Model_Name: MD1_MIN-Y_200-0.2-300-2__CEL-Adam_0.001.pt  \n",
    "Trainer:    Guille  \n",
    "## Data Processing:  \n",
    "    Divider:        DIVIDERS_MIN  \n",
    "    Clear Cover:    Yes  \n",
    "## Model Shape:  \n",
    "    Layer 1: Embedding:  \n",
    "        embed_dim:  200  \n",
    "        dropout:    0.2  \n",
    "    Layer 2: Dropout_embed:  \n",
    "        hidden_dim: 300  \n",
    "        num_layers: 2  \n",
    "## Training:  \n",
    "    criterion:      CrossEntropyLoss  \n",
    "    optimizer:      Adam  \n",
    "    lr:             0.001  \n",
    "    epochs:         300  \n",
    "    patience:       15  \n",
    "    total epochs:   None  \n",
    "    best loss:      None  \n",
    "Output sentence:    None  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MODEL                                  MODEL_NAME TRAINER  \\\n",
      "0   NaN                                         NaN     NaN   \n",
      "1   NaN                                         NaN     NaN   \n",
      "2   MD1  MD1_MIN-Y_200-0.2-300-2__CEL-Adam_0.001.pt  Guille   \n",
      "3   MD2   MD2_OG-Y_450-0.2-600-1__CEL-Adam_0.001.pt  Alvaro   \n",
      "4   MD3  MD3_ALL-Y_450-0.2-600-1__CEL-Adam_0.001.pt  Alvaro   \n",
      "\n",
      "     DATA PROCESSING          Unnamed: 4         Model Shape Unnamed: 6  \\\n",
      "0                NaN                 NaN  Layer 1: Embedding        NaN   \n",
      "1            Divider         Clear Cover           embed_dim    dropout   \n",
      "2       DIVIDERS_MIN  Yes (delete cover)                 200        0.2   \n",
      "3  DIVIDERS_ORIGINAL  Yes (delete cover)                 450        0.2   \n",
      "4       DIVIDERS_ALL  Yes (delete cover)                 450        0.2   \n",
      "\n",
      "               Unnamed: 7  Unnamed: 8          Training  ... Unnamed: 15  \\\n",
      "0  Layer 2: Dropout_embed         NaN               NaN  ...         NaN   \n",
      "1              hidden_dim  num_layers         criterion  ...   best loss   \n",
      "2                     300           2  CrossEntropyLoss  ...         NaN   \n",
      "3                     600           1  CrossEntropyLoss  ...         NaN   \n",
      "4                     600           1  CrossEntropyLoss  ...         NaN   \n",
      "\n",
      "                                     Output sentence Unnamed: 17 Unnamed: 18  \\\n",
      "0                                                NaN         NaN         NaN   \n",
      "1                                                NaN         NaN         NaN   \n",
      "2                                                NaN         NaN         NaN   \n",
      "3  I am a widower and never had any we live very ...         NaN         NaN   \n",
      "4  I am a widower fellow back so as to make the c...         NaN         NaN   \n",
      "\n",
      "  Unnamed: 19 Unnamed: 20 extra  Unnamed: 22  Unnamed: 23  Unnamed: 24  \n",
      "0         NaN         NaN   NaN          NaN          NaN          NaN  \n",
      "1         NaN         NaN   NaN          NaN          NaN          NaN  \n",
      "2         NaN         NaN   MIN            Y          CEL         Adam  \n",
      "3         NaN         NaN    OG            Y          CEL         Adam  \n",
      "4         NaN         NaN   ALL            Y          CEL         Adam  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TRABAJO\\Cognizant\\Project-III\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('model_tests.xlsx')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23 entries, 0 to 22\n",
      "Data columns (total 25 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   MODEL            21 non-null     object \n",
      " 1   MODEL_NAME       21 non-null     object \n",
      " 2   TRAINER          9 non-null      object \n",
      " 3   DATA PROCESSING  10 non-null     object \n",
      " 4   Unnamed: 4       10 non-null     object \n",
      " 5   Model Shape      11 non-null     object \n",
      " 6   Unnamed: 6       10 non-null     object \n",
      " 7   Unnamed: 7       11 non-null     object \n",
      " 8   Unnamed: 8       10 non-null     object \n",
      " 9   Training         10 non-null     object \n",
      " 10  Unnamed: 10      10 non-null     object \n",
      " 11  Unnamed: 11      10 non-null     object \n",
      " 12  Unnamed: 12      10 non-null     object \n",
      " 13  Unnamed: 13      10 non-null     object \n",
      " 14  Unnamed: 14      4 non-null      object \n",
      " 15  Unnamed: 15      4 non-null      object \n",
      " 16  Output sentence  7 non-null      object \n",
      " 17  Unnamed: 17      0 non-null      float64\n",
      " 18  Unnamed: 18      0 non-null      float64\n",
      " 19  Unnamed: 19      0 non-null      float64\n",
      " 20  Unnamed: 20      0 non-null      float64\n",
      " 21  extra            9 non-null      object \n",
      " 22  Unnamed: 22      9 non-null      object \n",
      " 23  Unnamed: 23      9 non-null      object \n",
      " 24  Unnamed: 24      9 non-null      object \n",
      "dtypes: float64(4), object(21)\n",
      "memory usage: 4.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:, :17]\n",
    "df = df.iloc[:11, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   MODEL            9 non-null      object\n",
      " 1   MODEL_NAME       9 non-null      object\n",
      " 2   TRAINER          9 non-null      object\n",
      " 3   DATA PROCESSING  10 non-null     object\n",
      " 4   Unnamed: 4       10 non-null     object\n",
      " 5   Model Shape      11 non-null     object\n",
      " 6   Unnamed: 6       10 non-null     object\n",
      " 7   Unnamed: 7       11 non-null     object\n",
      " 8   Unnamed: 8       10 non-null     object\n",
      " 9   Training         10 non-null     object\n",
      " 10  Unnamed: 10      10 non-null     object\n",
      " 11  Unnamed: 11      10 non-null     object\n",
      " 12  Unnamed: 12      10 non-null     object\n",
      " 13  Unnamed: 13      10 non-null     object\n",
      " 14  Unnamed: 14      4 non-null      object\n",
      " 15  Unnamed: 15      4 non-null      object\n",
      " 16  Output sentence  7 non-null      object\n",
      "dtypes: object(17)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['ID', 'MODEL_NAME', 'TRAINER', 'DIVIDER', 'CLEAR_COVER', 'EMBED_DIM',\n",
    "            'DROPOUT', 'HIDDEN_DIM', 'NUM_LAYERS', 'CRITERION', 'OPTIMIZER', 'LEARNING_RATE',\n",
    "            'EPOCHS', 'PATIENCE', 'TOTAL_EPOCHS', 'BEST_LOSS', 'OUTPUT_SENTENCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   NaN\n",
       "1                                                   NaN\n",
       "2                                                   NaN\n",
       "3     I am a widower and never had any we live very ...\n",
       "4     I am a widower fellow back so as to make the c...\n",
       "5     I am not still so short a theory as to me from...\n",
       "6     I am a man of honour and your address had been...\n",
       "7     I am a man who will certainly get seven penal ...\n",
       "8     I am a man who takes very little exercise upon...\n",
       "9     I am excuse to be a morose and silent but coul...\n",
       "10                                                  NaN\n",
       "Name: OUTPUT_SENTENCE, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['OUTPUT_SENTENCE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
